{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Setup and Initialization\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from google.colab import drive\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    BertPreTrainedModel,\n",
        "    BertModel\n",
        ")\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- KEY SETTINGS ---\n",
        "GDRIVE_PATH = '/content/drive/MyDrive/eecsi_revise/'\n",
        "SEED = 42\n",
        "\n",
        "print(f\"✅ Setup complete. Working inside folder: {GDRIVE_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhOC19mTw1Vl",
        "outputId": "7fc02f35-3dad-455b-8b5d-4b923a229d9b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Setup complete. Working inside folder: /content/drive/MyDrive/eecsi_revise/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Load Data and Initial ACD Predictions\n",
        "\n",
        "print(\"--- Loading base data and pre-generated ACD predictions ---\")\n",
        "\n",
        "try:\n",
        "    # Load the main dataframe\n",
        "    df = pd.read_csv(os.path.join(GDRIVE_PATH, 'final_golden_dataset_eecsi.csv'))\n",
        "\n",
        "    # Load the 5-fold split definitions\n",
        "    with open(os.path.join(GDRIVE_PATH, 'kfold_splits.pkl'), 'rb') as f:\n",
        "        kfold_splits = pickle.load(f)\n",
        "\n",
        "    # Load the raw predictions file which contains results from the ACD stage\n",
        "    # This file should have predictions for 'indobertweet_pipeline_acd'\n",
        "    with open(os.path.join(GDRIVE_PATH, 'all_model_predictions.pkl'), 'rb') as f:\n",
        "        all_predictions = pickle.load(f)\n",
        "\n",
        "    print(\"✅ All necessary files loaded successfully.\")\n",
        "    print(f\"Dataset loaded with {len(df)} rows.\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"❌ ERROR: A required file was not found. Details: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65L_eaGzw2j_",
        "outputId": "d9da29a0-1297-48c3-fddf-35d55e04d126"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading base data and pre-generated ACD predictions ---\n",
            "✅ All necessary files loaded successfully.\n",
            "Dataset loaded with 3030 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Generate ASC Predictions for the Best Pipeline Model (REVISED)\n",
        "\n",
        "class PredictionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings): self.encodings = encodings\n",
        "    def __getitem__(self, idx): return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    def __len__(self): return len(self.encodings.input_ids)\n",
        "\n",
        "print(\"\\n--- Generating predictions for the PIPELINE's ASC stage... ---\")\n",
        "ASC_MODEL_NAME = \"indolem/indobertweet-base-uncased\"\n",
        "ASC_RESULTS_PATH = os.path.join(GDRIVE_PATH, 'indobertweet_asc_results/')\n",
        "TEXT_COLUMN = 'full_text' if 'full_text' in df.columns else 'cleaned_text'\n",
        "\n",
        "relevant_df = df[df['aspect'] != 'Irrelevant'].copy()\n",
        "sentiment_labels_list = sorted(relevant_df['sentiment'].unique())\n",
        "s_label2id = {l: i for i, l in enumerate(sentiment_labels_list)}\n",
        "s_id2label = {i: l for i, l in enumerate(sentiment_labels_list)}\n",
        "\n",
        "tokenizer_asc = AutoTokenizer.from_pretrained(ASC_MODEL_NAME)\n",
        "asc_predictions = pd.Series([None] * len(relevant_df), index=relevant_df.index)\n",
        "\n",
        "skf_asc = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "for i, (train_index, test_index) in enumerate(skf_asc.split(relevant_df[TEXT_COLUMN], relevant_df['sentiment'])):\n",
        "    fold_num = i + 1\n",
        "    print(f\"  Processing Pipeline ASC Fold {fold_num}/5...\")\n",
        "    fold_dir = os.path.join(ASC_RESULTS_PATH, f'fold_{fold_num}')\n",
        "\n",
        "    # --- [FIX] More thorough logic to find the TRUE best checkpoint ---\n",
        "    try:\n",
        "        # For pipeline models, the structure is often simpler.\n",
        "        # Let's check the root of the fold directory first, as that's a common pattern.\n",
        "        state_path = os.path.join(fold_dir, 'trainer_state.json')\n",
        "        with open(state_path, 'r') as f:\n",
        "            state = json.load(f)\n",
        "        best_checkpoint_path = state['best_model_checkpoint']\n",
        "        print(f\"    ✅ Found best model via trainer_state.json in root: {os.path.basename(best_checkpoint_path)}\")\n",
        "    except (FileNotFoundError, KeyError):\n",
        "        # Fallback to the logic for nested checkpoint directories\n",
        "        try:\n",
        "            possible_checkpoints = [d for d in os.listdir(fold_dir) if d.startswith('checkpoint-') and os.path.isdir(os.path.join(fold_dir, d))]\n",
        "            latest_checkpoint_dir = sorted(possible_checkpoints, key=lambda x: int(x.split('-')[-1]))[-1]\n",
        "            state_path = os.path.join(fold_dir, latest_checkpoint_dir, 'trainer_state.json')\n",
        "            with open(state_path, 'r') as f:\n",
        "                state = json.load(f)\n",
        "            saved_best_path = state['best_model_checkpoint']\n",
        "            best_checkpoint_name = os.path.basename(saved_best_path)\n",
        "            best_checkpoint_path = os.path.join(fold_dir, best_checkpoint_name)\n",
        "            print(f\"    ✅ Found best model via nested trainer_state.json: {best_checkpoint_name}\")\n",
        "        except Exception as e:\n",
        "             print(f\"    ⚠️ Warning: Could not determine best model from any trainer_state.json (Reason: {e}). Using latest checkpoint as final fallback.\")\n",
        "             possible_checkpoints = [d for d in os.listdir(fold_dir) if d.startswith('checkpoint-')]\n",
        "             best_checkpoint_path = os.path.join(fold_dir, sorted(possible_checkpoints, key=lambda x: int(x.split('-')[-1]))[-1])\n",
        "    # --- END OF FIX ---\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(best_checkpoint_path)\n",
        "    trainer = Trainer(model=model)\n",
        "    test_data = relevant_df.iloc[test_index]\n",
        "    test_encodings = tokenizer_asc(list(test_data[TEXT_COLUMN]), truncation=True, padding=True, max_length=128)\n",
        "    prediction_dataset = PredictionDataset(test_encodings)\n",
        "    predictions = trainer.predict(prediction_dataset)\n",
        "    predicted_labels_int = np.argmax(predictions.predictions, axis=1)\n",
        "    asc_predictions.iloc[test_index] = predicted_labels_int\n",
        "\n",
        "final_asc_preds = asc_predictions.map(s_id2label)\n",
        "print(\"\\n✅ Pipeline ASC prediction generation complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "ELBScr5Mw49m",
        "outputId": "12227b9f-2455-4bcb-b63e-bd6a6f28fbaa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generating predictions for the PIPELINE's ASC stage... ---\n",
            "  Processing Pipeline ASC Fold 1/5...\n",
            "    ✅ Found best model via nested trainer_state.json: checkpoint-411\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing Pipeline ASC Fold 2/5...\n",
            "    ✅ Found best model via nested trainer_state.json: checkpoint-685\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing Pipeline ASC Fold 3/5...\n",
            "    ✅ Found best model via nested trainer_state.json: checkpoint-274\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing Pipeline ASC Fold 4/5...\n",
            "    ✅ Found best model via nested trainer_state.json: checkpoint-685\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing Pipeline ASC Fold 5/5...\n",
            "    ✅ Found best model via nested trainer_state.json: checkpoint-685\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Pipeline ASC prediction generation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Create Initial Analysis DataFrame\n",
        "\n",
        "print(\"--- Combining all data into a single analysis DataFrame ---\")\n",
        "df_analysis = pd.DataFrame({\n",
        "    'true_aspect': all_predictions['y_true'],\n",
        "    'pred_aspect_pipeline': all_predictions['indobertweet_pipeline_acd']\n",
        "})\n",
        "\n",
        "# Add the true sentiment and the newly generated pipeline ASC predictions\n",
        "df_analysis['true_sentiment'] = df['sentiment']\n",
        "df_analysis['pred_sentiment_pipeline'] = final_asc_preds\n",
        "\n",
        "print(\"✅ Initial df_analysis created with ground truth and pipeline predictions.\")\n",
        "display(df_analysis.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "As7VhuGKw7NY",
        "outputId": "66b91233-ca54-4bdd-c342-1ec83fad39cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Combining all data into a single analysis DataFrame ---\n",
            "✅ Initial df_analysis created with ground truth and pipeline predictions.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  true_aspect pred_aspect_pipeline true_sentiment pred_sentiment_pipeline\n",
              "0  Irrelevant           Irrelevant            NaN                     NaN\n",
              "1  Irrelevant        Smart Economy            NaN                     NaN\n",
              "2  Irrelevant           Irrelevant            NaN                     NaN\n",
              "3  Irrelevant           Irrelevant            NaN                     NaN\n",
              "4  Irrelevant           Irrelevant            NaN                     NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33c0c643-fbd9-48ea-a4e0-63af51c197a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>true_aspect</th>\n",
              "      <th>pred_aspect_pipeline</th>\n",
              "      <th>true_sentiment</th>\n",
              "      <th>pred_sentiment_pipeline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>Smart Economy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33c0c643-fbd9-48ea-a4e0-63af51c197a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33c0c643-fbd9-48ea-a4e0-63af51c197a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33c0c643-fbd9-48ea-a4e0-63af51c197a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-027d7b71-4930-455e-b7aa-1fba09130b5e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-027d7b71-4930-455e-b7aa-1fba09130b5e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-027d7b71-4930-455e-b7aa-1fba09130b5e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "BaOCT2iuqzjc",
        "outputId": "3576a5ef-5895-4ddd-e125-f433b2c65ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generating End-to-End predictions for the Joint (MTL) model ---\n",
            "Correct Aspect Label Mapping has been created:\n",
            "{0: 'Smart Economy', 1: 'Smart Environment', 2: 'Smart Governance', 3: 'Smart Living', 4: 'Smart Mobility', 5: 'Smart People'}\n",
            "  Processing MTL Fold 1/5...\n",
            "    ✅ Found best model via trainer_state.json: checkpoint-510\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing MTL Fold 2/5...\n",
            "    ✅ Found best model via trainer_state.json: checkpoint-408\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing MTL Fold 3/5...\n",
            "    ✅ Found best model via trainer_state.json: checkpoint-408\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing MTL Fold 4/5...\n",
            "    ✅ Found best model via trainer_state.json: checkpoint-408\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing MTL Fold 5/5...\n",
            "    ✅ Found best model via trainer_state.json: checkpoint-408\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ MTL end-to-end prediction generation complete.\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Generate End-to-End Predictions for the Best Joint Model (MTL) - FINAL CORRECTED VERSION\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import BertPreTrainedModel, BertModel, AutoTokenizer, Trainer\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "\n",
        "print(\"\\n--- Generating End-to-End predictions for the Joint (MTL) model ---\")\n",
        "\n",
        "# --- Full class definitions must be included ---\n",
        "class IndoBERT_MTL(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.aspect_classifier = nn.Linear(config.hidden_size, config.num_aspect_labels)\n",
        "        self.sentiment_classifier = nn.Linear(config.hidden_size, config.num_sentiment_labels)\n",
        "        self.init_weights()\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, aspect_labels=None, sentiment_labels=None, return_dict=None, **kwargs):\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, return_dict=return_dict)\n",
        "        pooled_output = outputs[1]; pooled_output = self.dropout(pooled_output)\n",
        "        aspect_logits = self.aspect_classifier(pooled_output); sentiment_logits = self.sentiment_classifier(pooled_output)\n",
        "        if aspect_labels is None:\n",
        "            return SequenceClassifierOutput(loss=None, logits=(aspect_logits, sentiment_logits), hidden_states=outputs.hidden_states, attentions=outputs.attentions)\n",
        "        else:\n",
        "            total_loss = 0; loss_fct = nn.CrossEntropyLoss()\n",
        "            total_loss += loss_fct(aspect_logits.view(-1, self.config.num_aspect_labels), aspect_labels.view(-1))\n",
        "            total_loss += loss_fct(sentiment_logits.view(-1, self.config.num_sentiment_labels), sentiment_labels.view(-1))\n",
        "            return SequenceClassifierOutput(loss=total_loss, logits=(aspect_logits, sentiment_logits), hidden_states=outputs.hidden_states, attentions=outputs.attentions)\n",
        "\n",
        "class PredictionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings): self.encodings = encodings\n",
        "    def __getitem__(self, idx): return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    def __len__(self): return len(self.encodings.input_ids)\n",
        "\n",
        "# --- Setup for MTL Prediction ---\n",
        "MTL_MODEL_NAME = \"indobenchmark/indobert-base-p1\"\n",
        "MTL_RESULTS_PATH = os.path.join(GDRIVE_PATH, 'mtl_indobert_results/')\n",
        "TEXT_COLUMN = 'full_text' if 'full_text' in df.columns else 'cleaned_text'\n",
        "\n",
        "# --- [!!! TINDAKAN DIPERLUKAN !!!] ---\n",
        "# GANTI BAGIAN INI DENGAN KAMUS LABEL ASPEK YANG BENAR DARI SCRIPT TRAINING ANDA\n",
        "# Kamus dinamis (sorted) yang menyebabkan masalah sudah saya beri komentar.\n",
        "\n",
        "# # (DO NOT USE THIS DYNAMIC MAPPING - It causes the error)\n",
        "# aspect_labels_list = sorted(df['aspect'].unique())\n",
        "# a_label2id = {l: i for i, l in enumerate(aspect_labels_list)}\n",
        "# a_id2label = {i: l for i, l in enumerate(aspect_labels_list)}\n",
        "\n",
        "# GANTI DENGAN KAMUS ID->LABEL (ANGKA KE STRING) YANG SESUAI DARI TRAINING SCRIPT ANDA\n",
        "# INI HANYA CONTOH, GUNAKAN MILIK ANDA:\n",
        "a_id2label_correct = {\n",
        "    0: 'Smart Economy', 1: 'Smart Environment', 2: 'Smart Governance',\n",
        "    3: 'Smart Living', 4: 'Smart Mobility', 5: 'Smart People'\n",
        "}\n",
        "\n",
        "print(\"Correct Aspect Label Mapping has been created:\")\n",
        "print(a_id2label_correct)\n",
        "# --- [AKHIR DARI BAGIAN YANG PERLU DIUBAH] ---\n",
        "\n",
        "\n",
        "# Sentiment mapping can remain dynamic as it was working correctly\n",
        "sentiment_labels_list_all = sorted(df[df['aspect'] != 'Irrelevant']['sentiment'].unique())\n",
        "s_id2label_all = {i: l for i, l in enumerate(sentiment_labels_list_all)}\n",
        "\n",
        "tokenizer_mtl = AutoTokenizer.from_pretrained(MTL_MODEL_NAME)\n",
        "mtl_aspect_preds = pd.Series([None] * len(df), index=df.index)\n",
        "mtl_sentiment_preds = pd.Series([None] * len(df), index=df.index)\n",
        "\n",
        "for i, fold_dict in enumerate(kfold_splits):\n",
        "    fold_num = i + 1\n",
        "    print(f\"  Processing MTL Fold {fold_num}/5...\")\n",
        "    test_index = fold_dict['test']\n",
        "    fold_dir = os.path.join(MTL_RESULTS_PATH, f'fold_{fold_num}')\n",
        "    try:\n",
        "        possible_checkpoints = [d for d in os.listdir(fold_dir) if d.startswith('checkpoint-') and os.path.isdir(os.path.join(fold_dir, d))]\n",
        "        latest_checkpoint_dir = sorted(possible_checkpoints, key=lambda x: int(x.split('-')[-1]))[-1]\n",
        "        state_path = os.path.join(fold_dir, latest_checkpoint_dir, 'trainer_state.json')\n",
        "        with open(state_path, 'r') as f: state = json.load(f)\n",
        "        saved_best_path = state['best_model_checkpoint']\n",
        "        best_checkpoint_name = os.path.basename(saved_best_path)\n",
        "        best_checkpoint_path = os.path.join(fold_dir, best_checkpoint_name)\n",
        "        print(f\"    ✅ Found best model via trainer_state.json: {os.path.basename(best_checkpoint_path)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ Warning: Could not determine best model from trainer_state.json (Reason: {e}). Using latest checkpoint as fallback.\")\n",
        "        possible_checkpoints = [d for d in os.listdir(fold_dir) if d.startswith('checkpoint-') and os.path.isdir(os.path.join(fold_dir, d))]\n",
        "        best_checkpoint_path = os.path.join(fold_dir, sorted(possible_checkpoints, key=lambda x: int(x.split('-')[-1]))[-1])\n",
        "\n",
        "    model_mtl = IndoBERT_MTL.from_pretrained(best_checkpoint_path)\n",
        "    trainer_mtl = Trainer(model=model_mtl)\n",
        "    test_data = df.iloc[test_index]\n",
        "    test_encodings = tokenizer_mtl(list(test_data[TEXT_COLUMN]), truncation=True, padding=True, max_length=128)\n",
        "    prediction_dataset = PredictionDataset(test_encodings)\n",
        "    predictions = trainer_mtl.predict(prediction_dataset)\n",
        "    aspect_logits, sentiment_logits = predictions.predictions\n",
        "    predicted_aspects_int = np.argmax(aspect_logits, axis=1)\n",
        "    predicted_sentiments_int = np.argmax(sentiment_logits, axis=1)\n",
        "    mtl_aspect_preds.iloc[test_index] = predicted_aspects_int\n",
        "    mtl_sentiment_preds.iloc[test_index] = predicted_sentiments_int\n",
        "\n",
        "# --- Pastikan mapping menggunakan kamus yang benar ---\n",
        "final_mtl_aspect_preds = mtl_aspect_preds.map(a_id2label_correct)\n",
        "final_mtl_sentiment_preds = mtl_sentiment_preds.map(s_id2label_all)\n",
        "\n",
        "df_analysis['pred_aspect_mtl'] = final_mtl_aspect_preds\n",
        "df_analysis['pred_sentiment_mtl'] = final_mtl_sentiment_preds\n",
        "\n",
        "print(\"\\n✅ MTL end-to-end prediction generation complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Final Deep-Dive Investigation and Analysis\n",
        "\n",
        "print(\"--- Starting Deep-Dive Investigation of the Anomaly ---\")\n",
        "# STEP 1: Isolate and clean data\n",
        "print(\"\\n[STEP 1] Isolating and Cleaning Data...\")\n",
        "df_investigation = df_analysis[df_analysis['true_aspect'] != 'Irrelevant'].copy()\n",
        "df_investigation['true_aspect_cleaned'] = df_investigation['true_aspect'].str.strip()\n",
        "df_investigation['true_sentiment_cleaned'] = df_investigation['true_sentiment'].str.strip()\n",
        "df_investigation['pred_aspect_mtl_cleaned'] = df_investigation['pred_aspect_mtl'].str.strip()\n",
        "df_investigation['pred_sentiment_mtl_cleaned'] = df_investigation['pred_sentiment_mtl'].str.strip()\n",
        "df_investigation['pred_aspect_pipeline_cleaned'] = df_investigation['pred_aspect_pipeline'].str.strip()\n",
        "df_investigation['pred_sentiment_pipeline_cleaned'] = df_investigation['pred_sentiment_pipeline'].str.strip()\n",
        "print(\"✅ All ground truth and prediction columns have been cleaned.\")\n",
        "\n",
        "# STEP 2: Perform separate comparisons\n",
        "print(\"\\n[STEP 2] Performing Separate Task Comparisons...\")\n",
        "df_investigation['debug_mtl_aspect_match'] = (df_investigation['pred_aspect_mtl_cleaned'] == df_investigation['true_aspect_cleaned'])\n",
        "df_investigation['debug_mtl_sentiment_match'] = (df_investigation['pred_sentiment_mtl_cleaned'] == df_investigation['true_sentiment_cleaned'])\n",
        "df_investigation['debug_pipeline_aspect_match'] = (df_investigation['pred_aspect_pipeline_cleaned'] == df_investigation['true_aspect_cleaned'])\n",
        "df_investigation['debug_pipeline_sentiment_match'] = (df_investigation['pred_sentiment_pipeline_cleaned'] == df_investigation['true_sentiment_cleaned'])\n",
        "print(\"✅ Debug columns created.\")\n",
        "\n",
        "# STEP 3: Calculate per-task accuracy\n",
        "print(\"\\n--- [DIAGNOSIS] Per-Task Accuracy ---\")\n",
        "mtl_aspect_acc = df_investigation['debug_mtl_aspect_match'].mean()\n",
        "mtl_sentiment_acc = df_investigation['debug_mtl_sentiment_match'].mean()\n",
        "pipeline_aspect_acc = df_investigation['debug_pipeline_aspect_match'].mean()\n",
        "pipeline_sentiment_acc = df_investigation['debug_pipeline_sentiment_match'].mean()\n",
        "print(f\"MTL Model -> Aspect Accuracy:      {mtl_aspect_acc:.2%}\")\n",
        "print(f\"MTL Model -> Sentiment Accuracy:   {mtl_sentiment_acc:.2%}\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Pipeline Model -> Aspect Accuracy:   {pipeline_aspect_acc:.2%}\")\n",
        "print(f\"Pipeline Model -> Sentiment Accuracy:{pipeline_sentiment_acc:.2%}\")\n",
        "\n",
        "# STEP 4: Recalculate Final End-to-End Accuracy & 'Lucky Guesses'\n",
        "print(\"\\n--- [FINAL CALCULATION] End-to-End Accuracy ---\")\n",
        "df_investigation['e2e_correct_mtl'] = df_investigation['debug_mtl_aspect_match'] & df_investigation['debug_mtl_sentiment_match']\n",
        "df_investigation['e2e_correct_pipeline'] = df_investigation['debug_pipeline_aspect_match'] & df_investigation['debug_pipeline_sentiment_match']\n",
        "e2e_accuracy_mtl = df_investigation['e2e_correct_mtl'].mean()\n",
        "e2e_accuracy_pipeline = df_investigation['e2e_correct_pipeline'].mean()\n",
        "performance_drop = e2e_accuracy_mtl - e2e_accuracy_pipeline\n",
        "print(f\"  - Joint Model (IndoBERT MTL):      {e2e_accuracy_mtl:.2%}\")\n",
        "print(f\"  - Pipeline Model (IndoBERTweet):   {e2e_accuracy_pipeline:.2%}\")\n",
        "print(f\"  --------------------------------------------------\")\n",
        "print(f\"  ==> Performance Drop of Pipeline vs. Joint Model: {performance_drop:.2%}\")\n",
        "\n",
        "print(\"\\n--- [FINAL CALCULATION] Pipeline's 'Lucky Guesses' ---\")\n",
        "# Create the pipeline correctness columns in the investigation df\n",
        "df_investigation['acd_correct'] = df_investigation['pred_aspect_pipeline_cleaned'] == df_investigation['true_aspect_cleaned']\n",
        "df_investigation['asc_correct'] = df_investigation['pred_sentiment_pipeline_cleaned'] == df_investigation['true_sentiment_cleaned']\n",
        "acd_wrong_df = df_investigation[df_investigation['acd_correct'] == False]\n",
        "lucky_guesses_count = acd_wrong_df['asc_correct'].sum()\n",
        "total_acd_errors = len(acd_wrong_df)\n",
        "if total_acd_errors > 0:\n",
        "    lucky_guess_percentage = (lucky_guesses_count / total_acd_errors)\n",
        "    print(f\"  ==> Percentage of 'lucky guesses' (correct ASC despite wrong ACD): {lucky_guess_percentage:.2%}\")\n",
        "else:\n",
        "    print(\"No ACD errors were found to analyze.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ4f81PLuv9-",
        "outputId": "d73cb4b9-565a-4980-9872-9e1921618f78"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Deep-Dive Investigation of the Anomaly ---\n",
            "\n",
            "[STEP 1] Isolating and Cleaning Data...\n",
            "✅ All ground truth and prediction columns have been cleaned.\n",
            "\n",
            "[STEP 2] Performing Separate Task Comparisons...\n",
            "✅ Debug columns created.\n",
            "\n",
            "--- [DIAGNOSIS] Per-Task Accuracy ---\n",
            "MTL Model -> Aspect Accuracy:      95.48%\n",
            "MTL Model -> Sentiment Accuracy:   94.85%\n",
            "------------------------------\n",
            "Pipeline Model -> Aspect Accuracy:   76.98%\n",
            "Pipeline Model -> Sentiment Accuracy:83.75%\n",
            "\n",
            "--- [FINAL CALCULATION] End-to-End Accuracy ---\n",
            "  - Joint Model (IndoBERT MTL):      91.26%\n",
            "  - Pipeline Model (IndoBERTweet):   64.56%\n",
            "  --------------------------------------------------\n",
            "  ==> Performance Drop of Pipeline vs. Joint Model: 26.71%\n",
            "\n",
            "--- [FINAL CALCULATION] Pipeline's 'Lucky Guesses' ---\n",
            "  ==> Percentage of 'lucky guesses' (correct ASC despite wrong ACD): 83.37%\n"
          ]
        }
      ]
    }
  ]
}